{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79d10d0",
   "metadata": {},
   "source": [
    "# Нагрузочное тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df3a2b",
   "metadata": {},
   "source": [
    "## Проверяем, насколько сегментация и ансамбль тяжелее обычной детекции при базовых настройках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd415572",
   "metadata": {},
   "source": [
    "perf_analyzer -m yolo_det -u triton:8001 -i grpc --concurrency-range 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2cb38",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 352\n",
    "    Throughput: 19.5553 infer/sec\n",
    "    Avg latency: 51069 usec (standard deviation 5532 usec)\n",
    "    p50 latency: 50658 usec\n",
    "    p90 latency: 56300 usec\n",
    "    p95 latency: 58710 usec\n",
    "    p99 latency: 70114 usec\n",
    "    Avg gRPC time: 51033 usec ((un)marshal request/response 451 usec + response wait 50582 usec)\n",
    "  Server:\n",
    "    Inference count: 352\n",
    "    Execution count: 352\n",
    "    Successful request count: 352\n",
    "    Avg request latency: 47411 usec (overhead 1121 usec + queue 87 usec + compute input 22 usec + compute infer 45770 usec + compute output 410 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 19.5553 infer/sec, latency 51069 usec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db150abe",
   "metadata": {},
   "source": [
    "perf_analyzer -m yolo_seg -u triton:8001 -i grpc --concurrency-range 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9d4db",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 248\n",
    "    Throughput: 13.7772 infer/sec\n",
    "    Avg latency: 72370 usec (standard deviation 6110 usec)\n",
    "    p50 latency: 72402 usec\n",
    "    p90 latency: 78587 usec\n",
    "    p95 latency: 82187 usec\n",
    "    p99 latency: 90401 usec\n",
    "    Avg gRPC time: 72247 usec ((un)marshal request/response 379 usec + response wait 71868 usec)\n",
    "  Server:\n",
    "    Inference count: 248\n",
    "    Execution count: 248\n",
    "    Successful request count: 248\n",
    "    Avg request latency: 66843 usec (overhead 1985 usec + queue 85 usec + compute input 23 usec + compute infer 63563 usec + compute output 1186 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 13.7772 infer/sec, latency 72370 usec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbd9d4",
   "metadata": {},
   "source": [
    "perf_analyzer -m yolo_ensemble -u triton:8001 -i grpc --concurrency-range 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21b31f",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 162\n",
    "    Throughput: 8.99854 infer/sec\n",
    "    Avg latency: 110399 usec (standard deviation 20575 usec)\n",
    "    p50 latency: 102887 usec\n",
    "    p90 latency: 143034 usec\n",
    "    p95 latency: 158234 usec\n",
    "    p99 latency: 176344 usec\n",
    "    Avg gRPC time: 110146 usec ((un)marshal request/response 528 usec + response wait 109618 usec)\n",
    "  Server:\n",
    "    Inference count: 162\n",
    "    Execution count: 162\n",
    "    Successful request count: 162\n",
    "    Avg request latency: 102849 usec (overhead 0 usec + queue 890 usec + compute 171226 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 163\n",
    "      Execution count: 163\n",
    "      Successful request count: 163\n",
    "      Avg request latency: 75435 usec (overhead 126 usec + queue 222 usec + compute input 19 usec + compute infer 74733 usec + compute output 334 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 162\n",
    "      Execution count: 162\n",
    "      Successful request count: 162\n",
    "      Avg request latency: 102569 usec (overhead 5762 usec + queue 668 usec + compute input 22 usec + compute infer 95378 usec + compute output 738 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 8.99854 infer/sec, latency 110399 usec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5de9c",
   "metadata": {},
   "source": [
    "Ансамбль работает в 2.1 раза медленнее одиночной детекции, так как выполняет последовательную (или параллельную) обработку двумя моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246c3f9",
   "metadata": {},
   "source": [
    "## Эксперимент 2: Влияние Batch Size (для yolo_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc1041",
   "metadata": {},
   "source": [
    "perf_analyzer -m yolo_det -u triton:8001 -i grpc -b 1\n",
    "\n",
    "\n",
    "\n",
    "perf_analyzer -m yolo_det -u triton:8001 -i grpc -b 4\n",
    "\n",
    "\n",
    "\n",
    "perf_analyzer -m yolo_det -u triton:8001 -i grpc -b 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd5320",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "Batch size: 1\n",
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 336\n",
    "    Throughput: 18.6633 infer/sec\n",
    "    Avg latency: 53568 usec (standard deviation 6458 usec)\n",
    "    p50 latency: 52792 usec\n",
    "    p90 latency: 60287 usec\n",
    "    p95 latency: 62322 usec\n",
    "    p99 latency: 72478 usec\n",
    "    Avg gRPC time: 53535 usec ((un)marshal request/response 522 usec + response wait 53013 usec)\n",
    "  Server:\n",
    "    Inference count: 336\n",
    "    Execution count: 336\n",
    "    Successful request count: 336\n",
    "    Avg request latency: 49918 usec (overhead 1225 usec + queue 86 usec + compute input 23 usec + compute infer 48120 usec + compute output 463 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 18.6633 infer/sec, latency 53568 usec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74e996",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "Batch size: 4\n",
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 102\n",
    "    Throughput: 22.6625 infer/sec\n",
    "    Avg latency: 176173 usec (standard deviation 20416 usec)\n",
    "    p50 latency: 171860 usec\n",
    "    p90 latency: 203500 usec\n",
    "    p95 latency: 220603 usec\n",
    "    p99 latency: 239641 usec\n",
    "    Avg gRPC time: 176141 usec ((un)marshal request/response 985 usec + response wait 175156 usec)\n",
    "  Server:\n",
    "    Inference count: 408\n",
    "    Execution count: 102\n",
    "    Successful request count: 102\n",
    "    Avg request latency: 162947 usec (overhead 2341 usec + queue 83 usec + compute input 22 usec + compute infer 158868 usec + compute output 1632 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 22.6625 infer/sec, latency 176173 usec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf8202",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    " Batch size: 8\n",
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 51\n",
    "    Throughput: 22.6603 infer/sec\n",
    "    Avg latency: 357137 usec (standard deviation 28305 usec)\n",
    "    p50 latency: 352764 usec\n",
    "    p90 latency: 383650 usec\n",
    "    p95 latency: 404678 usec\n",
    "    p99 latency: 487659 usec\n",
    "    Avg gRPC time: 357095 usec ((un)marshal request/response 1687 usec + response wait 355408 usec)\n",
    "  Server:\n",
    "    Inference count: 400\n",
    "    Execution count: 50\n",
    "    Successful request count: 50\n",
    "    Avg request latency: 337288 usec (overhead 5384 usec + queue 77 usec + compute input 21 usec + compute infer 328783 usec + compute output 3021 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 22.6603 infer/sec, latency 357137 usec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20c5ce",
   "metadata": {},
   "source": [
    "## Эксперимент 3: Параллельные запросы (Concurrency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06819e",
   "metadata": {},
   "source": [
    "perf_analyzer -m yolo_ensemble -u triton:8001 -i grpc --concurrency-range 1:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf92e37",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "** Measurement Settings ***\n",
    "  Batch size: 1\n",
    "  Service Kind: Triton\n",
    "  Using \"time_windows\" mode for stabilization\n",
    "  Measurement window: 5000 msec\n",
    "  Latency limit: 0 msec\n",
    "  Concurrency limit: 8 concurrent requests\n",
    "  Using synchronous calls for inference\n",
    "  Stabilizing using average latency\n",
    "\n",
    "Request concurrency: 1\n",
    "  Client: \n",
    "    Request count: 199\n",
    "    Throughput: 11.0515 infer/sec\n",
    "    Avg latency: 90611 usec (standard deviation 13410 usec)\n",
    "    p50 latency: 86912 usec\n",
    "    p90 latency: 107935 usec\n",
    "    p95 latency: 117139 usec\n",
    "    p99 latency: 133466 usec\n",
    "    Avg gRPC time: 90502 usec ((un)marshal request/response 478 usec + response wait 90024 usec)\n",
    "  Server:\n",
    "    Inference count: 199\n",
    "    Execution count: 199\n",
    "    Successful request count: 199\n",
    "    Avg request latency: 85295 usec (overhead 0 usec + queue 527 usec + compute 141086 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 199\n",
    "      Execution count: 199\n",
    "      Successful request count: 199\n",
    "      Avg request latency: 61859 usec (overhead 168 usec + queue 146 usec + compute input 30 usec + compute infer 61226 usec + compute output 288 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 199\n",
    "      Execution count: 199\n",
    "      Successful request count: 199\n",
    "      Avg request latency: 84964 usec (overhead 5042 usec + queue 381 usec + compute input 21 usec + compute infer 78883 usec + compute output 636 usec)\n",
    "\n",
    "Request concurrency: 2\n",
    "  Client: \n",
    "    Request count: 196\n",
    "    Throughput: 10.8889 infer/sec\n",
    "    Avg latency: 182854 usec (standard deviation 32590 usec)\n",
    "    p50 latency: 174244 usec\n",
    "    p90 latency: 220051 usec\n",
    "    p95 latency: 240754 usec\n",
    "    p99 latency: 299682 usec\n",
    "    Avg gRPC time: 182760 usec ((un)marshal request/response 540 usec + response wait 182220 usec)\n",
    "  Server:\n",
    "    Inference count: 196\n",
    "    Execution count: 196\n",
    "    Successful request count: 196\n",
    "    Avg request latency: 175684 usec (overhead 0 usec + queue 84457 usec + compute 152486 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 197\n",
    "      Execution count: 197\n",
    "      Successful request count: 197\n",
    "      Avg request latency: 66560 usec (overhead 24 usec + queue 581 usec + compute input 20 usec + compute infer 65675 usec + compute output 259 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 196\n",
    "      Execution count: 196\n",
    "      Successful request count: 196\n",
    "      Avg request latency: 175614 usec (overhead 5207 usec + queue 83876 usec + compute input 26 usec + compute infer 85811 usec + compute output 694 usec)\n",
    "\n",
    "Request concurrency: 3\n",
    "  Client: \n",
    "    Request count: 197\n",
    "    Throughput: 10.9439 infer/sec\n",
    "    Avg latency: 272021 usec (standard deviation 37643 usec)\n",
    "    p50 latency: 263388 usec\n",
    "    p90 latency: 311573 usec\n",
    "    p95 latency: 343479 usec\n",
    "    p99 latency: 420018 usec\n",
    "    Avg gRPC time: 271929 usec ((un)marshal request/response 537 usec + response wait 271392 usec)\n",
    "  Server:\n",
    "    Inference count: 197\n",
    "    Execution count: 197\n",
    "    Successful request count: 197\n",
    "    Avg request latency: 265294 usec (overhead 0 usec + queue 175474 usec + compute 151064 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 198\n",
    "      Execution count: 198\n",
    "      Successful request count: 198\n",
    "      Avg request latency: 66610 usec (overhead 25 usec + queue 1272 usec + compute input 22 usec + compute infer 64976 usec + compute output 314 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 197\n",
    "      Execution count: 197\n",
    "      Successful request count: 197\n",
    "      Avg request latency: 265224 usec (overhead 5271 usec + queue 174202 usec + compute input 22 usec + compute infer 84994 usec + compute output 734 usec)\n",
    "\n",
    "Request concurrency: 4\n",
    "  Client: \n",
    "    Request count: 201\n",
    "    Throughput: 11.1665 infer/sec\n",
    "    Avg latency: 358647 usec (standard deviation 39198 usec)\n",
    "    p50 latency: 348855 usec\n",
    "    p90 latency: 418348 usec\n",
    "    p95 latency: 454757 usec\n",
    "    p99 latency: 473095 usec\n",
    "    Avg gRPC time: 358533 usec ((un)marshal request/response 559 usec + response wait 357974 usec)\n",
    "  Server:\n",
    "    Inference count: 201\n",
    "    Execution count: 201\n",
    "    Successful request count: 201\n",
    "    Avg request latency: 351126 usec (overhead 0 usec + queue 261681 usec + compute 147665 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 201\n",
    "      Execution count: 201\n",
    "      Successful request count: 201\n",
    "      Avg request latency: 63460 usec (overhead 24 usec + queue 213 usec + compute input 19 usec + compute infer 62934 usec + compute output 269 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 201\n",
    "      Execution count: 201\n",
    "      Successful request count: 201\n",
    "      Avg request latency: 351057 usec (overhead 5147 usec + queue 261468 usec + compute input 21 usec + compute infer 83771 usec + compute output 649 usec)\n",
    "\n",
    "Request concurrency: 5\n",
    "  Client: \n",
    "    Request count: 189\n",
    "    Throughput: 10.4963 infer/sec\n",
    "    Avg latency: 473167 usec (standard deviation 43219 usec)\n",
    "    p50 latency: 467603 usec\n",
    "    p90 latency: 530563 usec\n",
    "    p95 latency: 547092 usec\n",
    "    p99 latency: 577216 usec\n",
    "    Avg gRPC time: 473063 usec ((un)marshal request/response 535 usec + response wait 472528 usec)\n",
    "  Server:\n",
    "    Inference count: 189\n",
    "    Execution count: 189\n",
    "    Successful request count: 189\n",
    "    Avg request latency: 465673 usec (overhead 0 usec + queue 371143 usec + compute 158885 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 190\n",
    "      Execution count: 190\n",
    "      Successful request count: 190\n",
    "      Avg request latency: 69801 usec (overhead 26 usec + queue 670 usec + compute input 20 usec + compute infer 68838 usec + compute output 247 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 189\n",
    "      Execution count: 189\n",
    "      Successful request count: 189\n",
    "      Avg request latency: 465603 usec (overhead 5350 usec + queue 370473 usec + compute input 24 usec + compute infer 89081 usec + compute output 674 usec)\n",
    "\n",
    "Request concurrency: 6\n",
    "  Client: \n",
    "    Request count: 205\n",
    "    Throughput: 11.3845 infer/sec\n",
    "    Avg latency: 527194 usec (standard deviation 42968 usec)\n",
    "    p50 latency: 516625 usec\n",
    "    p90 latency: 595184 usec\n",
    "    p95 latency: 615344 usec\n",
    "    p99 latency: 642747 usec\n",
    "    Avg gRPC time: 527089 usec ((un)marshal request/response 507 usec + response wait 526582 usec)\n",
    "  Server:\n",
    "    Inference count: 205\n",
    "    Execution count: 205\n",
    "    Successful request count: 205\n",
    "    Avg request latency: 520233 usec (overhead 0 usec + queue 432428 usec + compute 144749 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 205\n",
    "      Execution count: 205\n",
    "      Successful request count: 205\n",
    "      Avg request latency: 62670 usec (overhead 23 usec + queue 109 usec + compute input 19 usec + compute infer 62253 usec + compute output 264 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 205\n",
    "      Execution count: 205\n",
    "      Successful request count: 205\n",
    "      Avg request latency: 520163 usec (overhead 5633 usec + queue 432319 usec + compute input 22 usec + compute infer 81539 usec + compute output 650 usec)\n",
    "\n",
    "Request concurrency: 7\n",
    "  Client: \n",
    "    Request count: 189\n",
    "    Throughput: 10.4956 infer/sec\n",
    "    Avg latency: 662610 usec (standard deviation 64491 usec)\n",
    "    p50 latency: 643472 usec\n",
    "    p90 latency: 770010 usec\n",
    "    p95 latency: 819243 usec\n",
    "    p99 latency: 843866 usec\n",
    "    Avg gRPC time: 662513 usec ((un)marshal request/response 504 usec + response wait 662009 usec)\n",
    "  Server:\n",
    "    Inference count: 189\n",
    "    Execution count: 189\n",
    "    Successful request count: 189\n",
    "    Avg request latency: 655881 usec (overhead 0 usec + queue 561865 usec + compute 157625 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 190\n",
    "      Execution count: 190\n",
    "      Successful request count: 190\n",
    "      Avg request latency: 69424 usec (overhead 29 usec + queue 1069 usec + compute input 20 usec + compute infer 67992 usec + compute output 313 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 189\n",
    "      Execution count: 189\n",
    "      Successful request count: 189\n",
    "      Avg request latency: 655807 usec (overhead 5712 usec + queue 560796 usec + compute input 27 usec + compute infer 88612 usec + compute output 658 usec)\n",
    "\n",
    "Request concurrency: 8\n",
    "  Client: \n",
    "    Request count: 189\n",
    "    Throughput: 10.4976 infer/sec\n",
    "    Avg latency: 759170 usec (standard deviation 47749 usec)\n",
    "    p50 latency: 750999 usec\n",
    "    p90 latency: 823809 usec\n",
    "    p95 latency: 849497 usec\n",
    "    p99 latency: 876479 usec\n",
    "    Avg gRPC time: 759072 usec ((un)marshal request/response 521 usec + response wait 758551 usec)\n",
    "  Server:\n",
    "    Inference count: 189\n",
    "    Execution count: 189\n",
    "    Successful request count: 189\n",
    "    Avg request latency: 752384 usec (overhead 0 usec + queue 657841 usec + compute 159517 usec)\n",
    "\n",
    "  Composing models:\n",
    "  yolo_det, version: 1\n",
    "      Inference count: 190\n",
    "      Execution count: 190\n",
    "      Successful request count: 190\n",
    "      Avg request latency: 70893 usec (overhead 24 usec + queue 890 usec + compute input 21 usec + compute infer 69692 usec + compute output 265 usec)\n",
    "\n",
    "  yolo_seg, version: 1\n",
    "      Inference count: 189\n",
    "      Execution count: 189\n",
    "      Successful request count: 189\n",
    "      Avg request latency: 752309 usec (overhead 5820 usec + queue 656951 usec + compute input 23 usec + compute infer 88799 usec + compute output 715 usec)\n",
    "\n",
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 11.0515 infer/sec, latency 90611 usec\n",
    "Concurrency: 2, throughput: 10.8889 infer/sec, latency 182854 usec\n",
    "Concurrency: 3, throughput: 10.9439 infer/sec, latency 272021 usec\n",
    "Concurrency: 4, throughput: 11.1665 infer/sec, latency 358647 usec\n",
    "Concurrency: 5, throughput: 10.4963 infer/sec, latency 473167 usec\n",
    "Concurrency: 6, throughput: 11.3845 infer/sec, latency 527194 usec\n",
    "Concurrency: 7, throughput: 10.4956 infer/sec, latency 662610 usec\n",
    "Concurrency: 8, throughput: 10.4976 infer/sec, latency 759170 usec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7092ae",
   "metadata": {},
   "source": [
    "C Батчем 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fe449",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "perf_analyzer -m yolo_det -u triton:8001 -i grpc --concurrency-range 1:8 -b 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b32df",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "Inferences/Second vs. Client Average Batch Latency\n",
    "Concurrency: 1, throughput: 24.0545 infer/sec, latency 41530 usec\n",
    "Concurrency: 2, throughput: 24.6102 infer/sec, latency 80994 usec\n",
    "Concurrency: 3, throughput: 23.1066 infer/sec, latency 129753 usec\n",
    "Concurrency: 4, throughput: 22.3318 infer/sec, latency 178584 usec\n",
    "Concurrency: 5, throughput: 21.4949 infer/sec, latency 232006 usec\n",
    "Concurrency: 6, throughput: 20.7196 infer/sec, latency 289891 usec\n",
    "Concurrency: 7, throughput: 21.552 infer/sec, latency 323840 usec\n",
    "Concurrency: 8, throughput: 20.1666 infer/sec, latency 395933 usec"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
